# GPT


Decoder-only mini-LLM trained on roneneldan/TinyStories dataset.

For better performance, increase the parameters(# of attention heads, # of layers, embedding dimension, and TEMP variable) in the GPT_model.py file.


For training, run GPT_train.py.

For executing the newly trained model, run inference.py.
